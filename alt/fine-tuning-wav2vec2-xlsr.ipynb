{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dependencies Configuration","metadata":{}},{"cell_type":"code","source":"%env LC_ALL=C.UTF-8\n%env LANG=C.UTF-8\n%env TRANSFORMERS_CACHE=/content/cache\n%env HF_DATASETS_CACHE=/content/cache\n%env CUDA_LAUNCH_BLOCKING=1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install git+https://github.com/huggingface/datasets.git\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install torchaudio\n!pip install librosa\n!pip install jiwer\n!pip install wandb","metadata":{"id":"pWmoioQjhis7","execution":{"iopub.status.busy":"2022-04-01T04:49:19.752698Z","iopub.execute_input":"2022-04-01T04:49:19.753322Z","iopub.status.idle":"2022-04-01T04:51:13.233826Z","shell.execute_reply.started":"2022-04-01T04:49:19.753282Z","shell.execute_reply":"2022-04-01T04:51:13.232072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\n\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\n\nimport os\nimport string\nimport six\nimport re","metadata":{"id":"MMuAGi-Qhldz","execution":{"iopub.status.busy":"2022-04-01T04:51:51.567938Z","iopub.execute_input":"2022-04-01T04:51:51.568256Z","iopub.status.idle":"2022-04-01T04:51:51.574751Z","shell.execute_reply.started":"2022-04-01T04:51:51.568223Z","shell.execute_reply":"2022-04-01T04:51:51.573774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abs_path_to_data = \"../input/utterance-level\" #path to metadata json file\nabs_path_to_metadata = \"../input/metadata\" #path to audio files\noutput_path = \"./\" #output folder path","metadata":{"id":"do9XfS-fjDOM","execution":{"iopub.status.busy":"2022-04-01T04:51:59.700926Z","iopub.execute_input":"2022-04-01T04:51:59.701227Z","iopub.status.idle":"2022-04-01T04:51:59.707394Z","shell.execute_reply.started":"2022-04-01T04:51:59.701197Z","shell.execute_reply":"2022-04-01T04:51:59.706163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls {abs_path_to_metadata}/*.json","metadata":{"id":"J6aN-dc2jObP","outputId":"e6f50f43-2755-468e-d768-50324b099a31","execution":{"iopub.status.busy":"2022-04-01T04:52:03.544603Z","iopub.execute_input":"2022-04-01T04:52:03.544901Z","iopub.status.idle":"2022-04-01T04:52:04.305104Z","shell.execute_reply.started":"2022-04-01T04:52:03.54486Z","shell.execute_reply":"2022-04-01T04:52:04.303902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing and Tokenizer vocab creation","metadata":{}},{"cell_type":"code","source":"import json\n\nfile = open(f\"{abs_path_to_metadata}/metadata_split_by_song.json\",'r')\njson_data = file.read()\ndata = json.loads(json_data)\n\ntrain_df = pd.DataFrame()\ntest_df = pd.DataFrame()\nfor value in data.values():\n    res = {}\n    res[\"path\"] = f\"{abs_path_to_data}/{value['path']}/audio.wav\"\n    res[\"sentence\"] = value[\"lyrics\"]\n    if value[\"split\"]==\"train\":\n        train_df = train_df.append(res,ignore_index=True)\n    else:\n        test_df = test_df.append(res,ignore_index=True)\n\ntrain_df.to_csv(f\"{output_path}/train.tsv\",sep=\"\\t\")\ntest_df.to_csv(f\"{output_path}/test.tsv\",sep=\"\\t\")","metadata":{"id":"DRa_hYixELgd","execution":{"iopub.status.busy":"2022-04-01T04:52:06.179342Z","iopub.execute_input":"2022-04-01T04:52:06.179879Z","iopub.status.idle":"2022-04-01T04:52:16.947209Z","shell.execute_reply.started":"2022-04-01T04:52:06.179803Z","shell.execute_reply":"2022-04-01T04:52:16.946313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Custom normalizer for pre-processing the annotations \ndef normalizer(text):\n    # Use your custom normalizer\n    text = text.replace(\"\\\\n\",\"\\n\")\n    text = ' '.join(text.split())\n    text = re.sub(r'''(/|-|_)''',\" \", text)\n    text = text.strip()\n    return text","metadata":{"id":"_hhf9_NJkj88","execution":{"iopub.status.busy":"2022-04-01T04:52:21.290142Z","iopub.execute_input":"2022-04-01T04:52:21.290458Z","iopub.status.idle":"2022-04-01T04:52:21.296383Z","shell.execute_reply.started":"2022-04-01T04:52:21.290403Z","shell.execute_reply":"2022-04-01T04:52:21.295282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{output_path}/train.tsv\", sep=\"\\t\")\n_train_df = train_df.copy()\ntotal_records = len(train_df)\ntrain_df[\"id\"] = range(0, total_records)\nprint(f\"Step 0: {len(train_df)}\")\n\ntrain_df[\"status\"] = train_df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\ntrain_df = train_df.dropna(subset=[\"path\"])\ntrain_df = train_df.drop(\"status\", 1)\nprint(f\"Step 1: {len(train_df)}\")\n\ntrain_df[\"sentence\"] = train_df[\"sentence\"].apply(lambda t: normalizer(t))\ntrain_df = train_df.dropna(subset=[\"sentence\"])\nprint(f\"Step 2: {len(train_df)}\")\n\nterm_a = set(list(range(0, total_records)))\nterm_b = set(train_df[\"id\"].values.tolist())\nremoved_items_train = [_train_df.iloc[index][\"path\"] for index in list(term_a - term_b)]\ntrain_df = train_df.reset_index(drop=True)\ntrain_df.head()","metadata":{"id":"SVJJ5e7IjcMd","outputId":"1883e639-e11d-4dfc-8349-e880530e5434","execution":{"iopub.status.busy":"2022-04-01T04:52:38.753645Z","iopub.execute_input":"2022-04-01T04:52:38.754187Z","iopub.status.idle":"2022-04-01T04:52:47.847093Z","shell.execute_reply.started":"2022-04-01T04:52:38.75415Z","shell.execute_reply":"2022-04-01T04:52:47.846099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Items to be removed {len(removed_items_train)}\") #remove any items from the train set which can not be found","metadata":{"id":"Q0bv0kaXkpom","outputId":"c12b4355-e3f0-416b-9a7b-958aa8e23e93","execution":{"iopub.status.busy":"2022-04-01T04:52:52.83629Z","iopub.execute_input":"2022-04-01T04:52:52.836986Z","iopub.status.idle":"2022-04-01T04:52:52.842714Z","shell.execute_reply.started":"2022-04-01T04:52:52.836951Z","shell.execute_reply":"2022-04-01T04:52:52.841541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{output_path}/test.tsv\", sep=\"\\t\")\n\n_test_df = test_df.copy()\ntotal_records = len(test_df)\ntest_df[\"id\"] = range(0, total_records)\nprint(f\"Step 0: {len(test_df)}\")\n\ntest_df[\"status\"] = test_df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\ntest_df = test_df.dropna(subset=[\"path\"])\ntest_df = test_df.drop(\"status\", 1)\nprint(f\"Step 1: {len(test_df)}\")\n\ntest_df[\"sentence\"] = test_df[\"sentence\"].apply(lambda t: normalizer(t))\ntest_df = test_df.dropna(subset=[\"sentence\"])\nprint(f\"Step 2: {len(test_df)}\")\n\nterm_a = set(list(range(0, total_records)))\nterm_b = set(test_df[\"id\"].values.tolist())\nremoved_items_test = [_test_df.iloc[index][\"path\"] for index in list(term_a - term_b)]\ntest_df = test_df.reset_index(drop=True)\ntest_df.head()","metadata":{"id":"BAVrZeEilcCr","outputId":"a479dfae-f7d2-4590-d7c2-8de7c709d41d","execution":{"iopub.status.busy":"2022-04-01T04:53:02.704625Z","iopub.execute_input":"2022-04-01T04:53:02.704932Z","iopub.status.idle":"2022-04-01T04:53:04.283856Z","shell.execute_reply.started":"2022-04-01T04:53:02.704898Z","shell.execute_reply":"2022-04-01T04:53:04.282798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Items to be removed {len(removed_items_test)}\") #remove any items from the test set which can not be found","metadata":{"id":"PK0biZscll9v","outputId":"16c3f67c-bb22-4d8f-e3e4-a876599c7e05","execution":{"iopub.status.busy":"2022-04-01T04:53:06.157605Z","iopub.execute_input":"2022-04-01T04:53:06.157884Z","iopub.status.idle":"2022-04-01T04:53:06.165208Z","shell.execute_reply.started":"2022-04-01T04:53:06.157852Z","shell.execute_reply":"2022-04-01T04:53:06.163311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"removed_items = removed_items_train + removed_items_test\n\nfor path in removed_items:\n    if os.path.exists(path):\n        os.remove(path)","metadata":{"id":"4rYYwvVelp2O","execution":{"iopub.status.busy":"2022-04-01T04:53:07.921837Z","iopub.execute_input":"2022-04-01T04:53:07.922401Z","iopub.status.idle":"2022-04-01T04:53:07.929755Z","shell.execute_reply.started":"2022-04-01T04:53:07.922367Z","shell.execute_reply":"2022-04-01T04:53:07.928679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \" \".join(train_df[\"sentence\"].values.tolist() + test_df[\"sentence\"].values.tolist())\nvocab = list(sorted(set(text)))\n\nprint(len(vocab), vocab)","metadata":{"id":"bTGFN6YCltBY","outputId":"a0085119-d466-4ea7-a514-9fc05e6a16ba","execution":{"iopub.status.busy":"2022-04-01T04:53:10.14994Z","iopub.execute_input":"2022-04-01T04:53:10.150242Z","iopub.status.idle":"2022-04-01T04:53:10.159409Z","shell.execute_reply.started":"2022-04-01T04:53:10.150196Z","shell.execute_reply":"2022-04-01T04:53:10.15787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchaudio\nimport librosa\nimport IPython.display as ipd\nimport numpy as np\n\nsample = train_df.iloc[np.random.randint(0, len(train_df))]\n\npath = sample[\"path\"]\nprint(sample[\"sentence\"], \"\\n\")\nspeech,sample_rate = torchaudio.load(path)\nspeech = speech[0].numpy().squeeze()\n\nspeech = librosa.resample(np.asarray(speech), sample_rate, 16_000)\nipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)","metadata":{"id":"WlT-Rf8xlwHj","outputId":"64dffc3b-0a2e-4f68-a7c6-84bfb6130b04","execution":{"iopub.status.busy":"2022-04-01T04:53:11.900759Z","iopub.execute_input":"2022-04-01T04:53:11.901594Z","iopub.status.idle":"2022-04-01T04:53:15.639395Z","shell.execute_reply.started":"2022-04-01T04:53:11.901558Z","shell.execute_reply":"2022-04-01T04:53:15.637094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop('Unnamed: 0',axis=1)\ntest_df = test_df.drop('Unnamed: 0',axis=1)\ntrain_df.to_csv(f\"{output_path}/train.csv\", encoding=\"utf-8\", index=False)\ntest_df.to_csv(f\"{output_path}/test.csv\", encoding=\"utf-8\", index=False)\n\nprint(train_df.shape)\nprint(test_df.shape)","metadata":{"id":"VABtn4_Wl20Z","outputId":"80092041-4a5c-4a6f-96d6-a9c497840578","execution":{"iopub.status.busy":"2022-04-01T04:54:14.670324Z","iopub.execute_input":"2022-04-01T04:54:14.670605Z","iopub.status.idle":"2022-04-01T04:54:14.705547Z","shell.execute_reply.started":"2022-04-01T04:54:14.670574Z","shell.execute_reply":"2022-04-01T04:54:14.704496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice_train = load_dataset(\"csv\", data_files={\"train\": f\"{output_path}/train.csv\"})[\"train\"]\ncommon_voice_test = load_dataset(\"csv\", data_files={\"test\": f\"{output_path}/test.csv\"})[\"test\"]\n\nprint(common_voice_train)\nprint(common_voice_test)","metadata":{"id":"5T5lHNN-mK3n","outputId":"35a2b3cf-a351-4917-9dd1-922d0bac7238","execution":{"iopub.status.busy":"2022-04-01T04:54:39.062523Z","iopub.execute_input":"2022-04-01T04:54:39.062811Z","iopub.status.idle":"2022-04-01T04:54:40.363195Z","shell.execute_reply.started":"2022-04-01T04:54:39.062778Z","shell.execute_reply":"2022-04-01T04:54:40.36214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    display(HTML(df.to_html()))","metadata":{"id":"LUTNAkdkmmG9","execution":{"iopub.status.busy":"2022-04-01T04:54:54.936531Z","iopub.execute_input":"2022-04-01T04:54:54.936873Z","iopub.status.idle":"2022-04-01T04:54:54.945693Z","shell.execute_reply.started":"2022-04-01T04:54:54.936822Z","shell.execute_reply":"2022-04-01T04:54:54.943772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_random_elements(common_voice_train.remove_columns([\"path\"]), num_examples=20)","metadata":{"id":"JqUJ48n9m05g","outputId":"e3cb5d1f-6e19-4914-d38a-fd6393ae8bf4","execution":{"iopub.status.busy":"2022-04-01T04:54:58.709078Z","iopub.execute_input":"2022-04-01T04:54:58.709396Z","iopub.status.idle":"2022-04-01T04:54:58.726209Z","shell.execute_reply.started":"2022-04-01T04:54:58.709365Z","shell.execute_reply":"2022-04-01T04:54:58.725115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\_\\;\\:\\\"\\“\\%\\‘\\”\\।\\’\\']'\n\ndef remove_special_characters(batch):\n    text = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n    text = normalizer(text)\n    batch[\"text\"] = text\n    return batch","metadata":{"id":"_uolHTemm3d6","execution":{"iopub.status.busy":"2022-04-01T04:55:02.696367Z","iopub.execute_input":"2022-04-01T04:55:02.696648Z","iopub.status.idle":"2022-04-01T04:55:02.70362Z","shell.execute_reply.started":"2022-04-01T04:55:02.696616Z","shell.execute_reply":"2022-04-01T04:55:02.701973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice_train = common_voice_train.map(remove_special_characters, remove_columns=[\"sentence\"])\ncommon_voice_test = common_voice_test.map(remove_special_characters, remove_columns=[\"sentence\"])","metadata":{"id":"izqVJ81wm74x","outputId":"dc33689d-f88f-46ff-9d4e-34657453cddb","execution":{"iopub.status.busy":"2022-04-01T04:55:05.478055Z","iopub.execute_input":"2022-04-01T04:55:05.478377Z","iopub.status.idle":"2022-04-01T04:55:06.261401Z","shell.execute_reply.started":"2022-04-01T04:55:05.478314Z","shell.execute_reply":"2022-04-01T04:55:06.260384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_all_chars(batch):\n    all_text = \" \".join(batch[\"text\"])\n    vocab = list(set(all_text))\n    return {\"vocab\": [vocab], \"all_text\": [all_text]}","metadata":{"id":"LuICfFvFnBTL","execution":{"iopub.status.busy":"2022-04-01T04:55:14.599055Z","iopub.execute_input":"2022-04-01T04:55:14.599954Z","iopub.status.idle":"2022-04-01T04:55:14.606409Z","shell.execute_reply.started":"2022-04-01T04:55:14.599882Z","shell.execute_reply":"2022-04-01T04:55:14.605238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)\nvocab_test = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)","metadata":{"id":"onXiBku9nJfN","outputId":"e297cc7c-81f5-4dc9-a7ef-632746ff6a3b","execution":{"iopub.status.busy":"2022-04-01T04:55:18.081374Z","iopub.execute_input":"2022-04-01T04:55:18.081676Z","iopub.status.idle":"2022-04-01T04:55:18.22463Z","shell.execute_reply.started":"2022-04-01T04:55:18.081643Z","shell.execute_reply":"2022-04-01T04:55:18.223615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))","metadata":{"id":"-_hpGO_snEKp","execution":{"iopub.status.busy":"2022-04-01T04:55:20.741742Z","iopub.execute_input":"2022-04-01T04:55:20.742229Z","iopub.status.idle":"2022-04-01T04:55:20.749933Z","shell.execute_reply.started":"2022-04-01T04:55:20.742192Z","shell.execute_reply":"2022-04-01T04:55:20.748921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dict = {v: k for k, v in enumerate(vocab_list)}\nvocab_dict","metadata":{"id":"9yki-gFwnGNG","outputId":"7fda5d71-589e-4852-8fcf-5a0b0362fd1f","execution":{"iopub.status.busy":"2022-04-01T04:55:21.978287Z","iopub.execute_input":"2022-04-01T04:55:21.979477Z","iopub.status.idle":"2022-04-01T04:55:21.98935Z","shell.execute_reply.started":"2022-04-01T04:55:21.979429Z","shell.execute_reply":"2022-04-01T04:55:21.988113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dict[\"|\"] = vocab_dict[\" \"]\ndel vocab_dict[\" \"]","metadata":{"id":"L3NcNrfCoxQY","execution":{"iopub.status.busy":"2022-04-01T04:55:24.861757Z","iopub.execute_input":"2022-04-01T04:55:24.86221Z","iopub.status.idle":"2022-04-01T04:55:24.867174Z","shell.execute_reply.started":"2022-04-01T04:55:24.862178Z","shell.execute_reply":"2022-04-01T04:55:24.865875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dict[\"[UNK]\"] = len(vocab_dict)\nvocab_dict[\"[PAD]\"] = len(vocab_dict)\nlen(vocab_dict)","metadata":{"id":"KjAixStRo2dU","outputId":"4bf3aef0-69f7-4405-dae1-f7634fcb87f2","execution":{"iopub.status.busy":"2022-04-01T04:55:25.913705Z","iopub.execute_input":"2022-04-01T04:55:25.914582Z","iopub.status.idle":"2022-04-01T04:55:25.923713Z","shell.execute_reply.started":"2022-04-01T04:55:25.914546Z","shell.execute_reply":"2022-04-01T04:55:25.922681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)","metadata":{"id":"XOcr431xo4Hr","execution":{"iopub.status.busy":"2022-04-01T04:55:27.651191Z","iopub.execute_input":"2022-04-01T04:55:27.651488Z","iopub.status.idle":"2022-04-01T04:55:27.657089Z","shell.execute_reply.started":"2022-04-01T04:55:27.651457Z","shell.execute_reply":"2022-04-01T04:55:27.656077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training of the model","metadata":{}},{"cell_type":"code","source":"!mkdir -p ./dataset","metadata":{"id":"KYE_IT41o52Z","execution":{"iopub.status.busy":"2022-04-01T04:55:41.975841Z","iopub.execute_input":"2022-04-01T04:55:41.976162Z","iopub.status.idle":"2022-04-01T04:55:42.710668Z","shell.execute_reply.started":"2022-04-01T04:55:41.976129Z","shell.execute_reply":"2022-04-01T04:55:42.709514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = []\n\nfor item in tqdm(common_voice_train, position=0, total=len(common_voice_train)):\n    features = common_voice_train.features\n    data = {}\n    for key in features:\n        data[key] = item[key]\n    \n    trainset.append(data)\n\ntrainset = pd.DataFrame(trainset)\ntrainset.to_csv(\"./dataset/train.csv\", sep=\"\\t\")\n\n\ntestset = []\n\nfor item in tqdm(common_voice_test, position=0, total=len(common_voice_test)):\n    features = common_voice_test.features\n    data = {}\n    for key in features:\n        data[key] = item[key]\n    \n    testset.append(data)\n\ntestset = pd.DataFrame(testset)\ntestset.to_csv(\"./dataset/test.csv\", sep=\"\\t\")","metadata":{"id":"DqXdTpOEo7gX","outputId":"bf1963a3-dece-4d9f-c6ab-b44657ef172b","execution":{"iopub.status.busy":"2022-04-01T04:55:55.558589Z","iopub.execute_input":"2022-04-01T04:55:55.558905Z","iopub.status.idle":"2022-04-01T04:55:56.089542Z","shell.execute_reply.started":"2022-04-01T04:55:55.558875Z","shell.execute_reply":"2022-04-01T04:55:56.088362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset.head()","metadata":{"id":"Rzt_aWSNpApg","outputId":"57d6f1d5-0d1d-416b-847c-f428134f47da","execution":{"iopub.status.busy":"2022-04-01T04:56:00.852096Z","iopub.execute_input":"2022-04-01T04:56:00.852455Z","iopub.status.idle":"2022-04-01T04:56:00.865787Z","shell.execute_reply.started":"2022-04-01T04:56:00.852423Z","shell.execute_reply":"2022-04-01T04:56:00.864368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset.head()","metadata":{"id":"Y-yGxV9JpOAX","outputId":"77eff8f1-6239-4ae4-d84f-cdf6c3da3dba","execution":{"iopub.status.busy":"2022-04-01T04:56:01.412946Z","iopub.execute_input":"2022-04-01T04:56:01.413792Z","iopub.status.idle":"2022-04-01T04:56:01.425535Z","shell.execute_reply.started":"2022-04-01T04:56:01.413753Z","shell.execute_reply":"2022-04-01T04:56:01.424492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining a directory to save the trained model and other files\nsave_dir = \"./wav2vec2-large-xlsr-singing_new\"\n!ls {save_dir}","metadata":{"id":"EK2uMxphpQtr","outputId":"778e6ad3-42cd-4673-d210-fbda3b9c3164","execution":{"iopub.status.busy":"2022-04-01T15:05:01.629831Z","iopub.execute_input":"2022-04-01T15:05:01.630172Z","iopub.status.idle":"2022-04-01T15:05:02.886585Z","shell.execute_reply.started":"2022-04-01T15:05:01.630141Z","shell.execute_reply":"2022-04-01T15:05:02.885311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers.trainer_utils import get_last_checkpoint\n\nlast_checkpoint = None\n\nif os.path.exists(save_dir):\n    last_checkpoint = get_last_checkpoint(save_dir)\n    \nprint(last_checkpoint if last_checkpoint else 0)","metadata":{"id":"UvHqHHLPpVN8","outputId":"1b792fc1-ca5c-476f-86e1-d3c097fc5703","execution":{"iopub.status.busy":"2022-04-01T15:05:07.865993Z","iopub.execute_input":"2022-04-01T15:05:07.86631Z","iopub.status.idle":"2022-04-01T15:05:07.87569Z","shell.execute_reply.started":"2022-04-01T15:05:07.866275Z","shell.execute_reply":"2022-04-01T15:05:07.874445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading tokenizer from saved directory if it exists\nfrom transformers import Wav2Vec2CTCTokenizer\n\nif not os.path.exists(save_dir):\n    print(\"NotExist\")\n    tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\nelse:\n    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(save_dir)","metadata":{"id":"7KCm9GTtpckp","outputId":"65c469f3-3be8-4faf-a138-2b1411fc2fe1","execution":{"iopub.status.busy":"2022-04-01T15:05:10.785306Z","iopub.execute_input":"2022-04-01T15:05:10.785635Z","iopub.status.idle":"2022-04-01T15:05:10.802203Z","shell.execute_reply.started":"2022-04-01T15:05:10.785603Z","shell.execute_reply":"2022-04-01T15:05:10.800851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading feature extractor from saved directory if it exists\nfrom transformers import Wav2Vec2FeatureExtractor\n\nif not os.path.exists(save_dir):\n    print(\"NotExist\")\n    feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\nelse:\n    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(save_dir)","metadata":{"id":"cm7Dio3xpoaX","execution":{"iopub.status.busy":"2022-04-01T15:05:15.408934Z","iopub.execute_input":"2022-04-01T15:05:15.409311Z","iopub.status.idle":"2022-04-01T15:05:15.419134Z","shell.execute_reply.started":"2022-04-01T15:05:15.409278Z","shell.execute_reply":"2022-04-01T15:05:15.418002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a processor with the feature extractor and tokenizer defined above\nfrom transformers import Wav2Vec2Processor\n\nif not os.path.exists(save_dir):\n    print(\"NotExist\")\n    processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\nelse:\n    processor = Wav2Vec2Processor.from_pretrained(save_dir)","metadata":{"id":"n0ma45VSpgUk","outputId":"e407c1c0-db41-4b66-de88-09d7423f2be6","execution":{"iopub.status.busy":"2022-04-01T15:05:17.110876Z","iopub.execute_input":"2022-04-01T15:05:17.111269Z","iopub.status.idle":"2022-04-01T15:05:17.119968Z","shell.execute_reply.started":"2022-04-01T15:05:17.111236Z","shell.execute_reply":"2022-04-01T15:05:17.118878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(save_dir):\n    print(\"NotExist\")\n    processor.save_pretrained(save_dir)\n    print(\"Saved!\")","metadata":{"id":"pK6URQ2MpiA2","execution":{"iopub.status.busy":"2022-04-01T15:05:18.538071Z","iopub.execute_input":"2022-04-01T15:05:18.538455Z","iopub.status.idle":"2022-04-01T15:05:18.555051Z","shell.execute_reply.started":"2022-04-01T15:05:18.538422Z","shell.execute_reply":"2022-04-01T15:05:18.553895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice_train[0]","metadata":{"id":"0SS1HaLWprDO","outputId":"a1b86aaf-f61f-42dd-9f5f-726d125cffff","execution":{"iopub.status.busy":"2022-04-01T15:05:27.257882Z","iopub.execute_input":"2022-04-01T15:05:27.25829Z","iopub.status.idle":"2022-04-01T15:05:27.280876Z","shell.execute_reply.started":"2022-04-01T15:05:27.258257Z","shell.execute_reply":"2022-04-01T15:05:27.279134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to convert speech to a numpy array","metadata":{}},{"cell_type":"code","source":"import torchaudio\nimport librosa\nimport numpy as np\n\n\ndef speech_file_to_array_fn(file_path):\n    speech_array, _ = torchaudio.load(file_path)\n\n    speech_array = speech_array[0].numpy()\n    speech_array = librosa.resample(np.asarray(speech_array), 48_000, 16_000)\n    sampling_rate = 16_000\n\n    return speech_array, sampling_rate","metadata":{"id":"0OgMMRFtptOO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing an audio sample after it is converted into a suitable format","metadata":{}},{"cell_type":"code","source":"import IPython.display as ipd\nimport numpy as np\nimport random\n\nrand_int = random.randint(0, len(trainset))\nsample = trainset.iloc[rand_int]\n\ntext = sample[\"text\"]\npath = sample[\"path\"]\n\nspeech_array, sampling_rate = speech_file_to_array_fn(path)\n\nprint(\"Target text:\", text)\nprint(\"Input array shape:\", np.asarray(speech_array).shape)\nprint(\"Sampling rate:\", sampling_rate)\nprint()\n\nipd.Audio(data=np.asarray(speech_array), autoplay=True, rate=16000)","metadata":{"id":"MWu4S_UOqXbD","outputId":"ca5c52f4-adce-4a50-d318-e6cd06c699bb","execution":{"iopub.status.busy":"2022-04-01T15:06:37.366765Z","iopub.execute_input":"2022-04-01T15:06:37.367122Z","iopub.status.idle":"2022-04-01T15:06:37.542701Z","shell.execute_reply.started":"2022-04-01T15:06:37.367088Z","shell.execute_reply":"2022-04-01T15:06:37.541291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchaudio\nimport librosa\n\nimport numpy as np\nimport pandas as pd\n\nfrom torch.utils.data import Dataset, DataLoader\nimport os\n\n\nclass CommonVoiceDataset(Dataset):\n\n    def __init__(self, csv_file, root_dir, processor, column_names=None, sep=\"\\t\"):\n        self.data = pd.read_csv(os.path.join(root_dir, csv_file), sep=sep)\n        self.processor = processor\n        self.column_names = column_names\n\n    def __len__(self):\n        return len(self.data)\n\n\n    def speech_file_to_array_fn(self, batch):\n        speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n        batch[\"speech\"] = speech_array[0].numpy()\n        batch[\"sampling_rate\"] = sampling_rate\n        batch[\"target_text\"] = batch[\"text\"]\n        return batch\n\n    \n    def resample(self, batch):\n        batch[\"speech\"] = librosa.resample(np.asarray(batch[\"speech\"]), 48_000, 16_000)\n        batch[\"sampling_rate\"] = 16_000\n        return batch\n\n    \n    def prepare_dataset(self, batch, column_names=None):\n        batch[\"input_values\"] = self.processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"]).input_values[0].tolist()\n\n        with self.processor.as_target_processor():\n            batch[\"labels\"] = self.processor(batch[\"target_text\"]).input_ids\n\n        if column_names and isinstance(column_names, list):\n            batch = {name: batch[name] for name in column_names}\n        \n        return batch\n\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        batch = self.data.iloc[idx].copy()\n        batch = batch.to_dict()\n        batch = self.speech_file_to_array_fn(batch)\n        batch = self.resample(batch)\n        batch = self.prepare_dataset(batch, self.column_names)\n\n        return batch ","metadata":{"id":"0yKcI3xuqbX1","execution":{"iopub.status.busy":"2022-04-01T15:06:49.369196Z","iopub.execute_input":"2022-04-01T15:06:49.369532Z","iopub.status.idle":"2022-04-01T15:06:49.394041Z","shell.execute_reply.started":"2022-04-01T15:06:49.369502Z","shell.execute_reply":"2022-04-01T15:06:49.392891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    \"\"\"\n    Data collator that will dynamically pad the inputs received.\n    Args:\n        processor (:class:`~transformers.Wav2Vec2Processor`)\n            The processor used for proccessing the data.\n        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n            among:\n            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n              sequence if provided).\n            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n              maximum acceptable input length for the model if that argument is not provided.\n            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n              different lengths).\n        max_length (:obj:`int`, `optional`):\n            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n        max_length_labels (:obj:`int`, `optional`):\n            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n        pad_to_multiple_of (:obj:`int`, `optional`):\n            If set will pad the sequence to a multiple of the provided value.\n            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n            7.5 (Volta).\n    \"\"\"\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n    max_length: Optional[int] = None\n    max_length_labels: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    pad_to_multiple_of_labels: Optional[int] = None\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lenghts and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                max_length=self.max_length_labels,\n                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"id":"yAX0J10qqmg0","execution":{"iopub.status.busy":"2022-04-01T15:06:52.132344Z","iopub.execute_input":"2022-04-01T15:06:52.13275Z","iopub.status.idle":"2022-04-01T15:06:52.1549Z","shell.execute_reply.started":"2022-04-01T15:06:52.132704Z","shell.execute_reply":"2022-04-01T15:06:52.153861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"id":"G-z_34SIqqDP","execution":{"iopub.status.busy":"2022-04-01T15:06:54.607638Z","iopub.execute_input":"2022-04-01T15:06:54.607913Z","iopub.status.idle":"2022-04-01T15:06:54.616814Z","shell.execute_reply.started":"2022-04-01T15:06:54.607882Z","shell.execute_reply":"2022-04-01T15:06:54.615911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CommonVoiceDataset(\"train.csv\", \"./dataset/\", processor=processor, column_names=[\"input_values\", \"labels\"])\ntest_dataset = CommonVoiceDataset(\"test.csv\", \"./dataset/\", processor=processor, column_names=[\"input_values\", \"labels\"])","metadata":{"id":"n4c9pXGOqsdQ","execution":{"iopub.status.busy":"2022-04-01T15:06:54.99805Z","iopub.execute_input":"2022-04-01T15:06:54.998412Z","iopub.status.idle":"2022-04-01T15:06:55.024357Z","shell.execute_reply.started":"2022-04-01T15:06:54.998365Z","shell.execute_reply":"2022-04-01T15:06:55.023368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))\nprint(len(test_dataset))","metadata":{"id":"hFsNElVKquWW","outputId":"eac82538-ed47-49e6-b36a-62e29e541b2f","execution":{"iopub.status.busy":"2022-04-01T15:02:42.501075Z","iopub.execute_input":"2022-04-01T15:02:42.501382Z","iopub.status.idle":"2022-04-01T15:02:42.512311Z","shell.execute_reply.started":"2022-04-01T15:02:42.50135Z","shell.execute_reply":"2022-04-01T15:02:42.5105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_dataset:\n    print(batch.keys())\n    print(type(batch))\n    # print(batch)\n    break","metadata":{"id":"2B-Jq2kDqwYg","outputId":"49edd2d0-5c37-4257-c846-825066217627","execution":{"iopub.status.busy":"2022-04-01T15:07:22.773163Z","iopub.execute_input":"2022-04-01T15:07:22.77402Z","iopub.status.idle":"2022-04-01T15:07:22.876667Z","shell.execute_reply.started":"2022-04-01T15:07:22.773983Z","shell.execute_reply":"2022-04-01T15:07:22.875475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wer_metric = load_metric(\"wer\")","metadata":{"id":"R9End5sEqyxE","outputId":"9594467b-50d4-4d79-d4da-4e2bd93c7305","execution":{"iopub.status.busy":"2022-04-01T15:07:25.802511Z","iopub.execute_input":"2022-04-01T15:07:25.8029Z","iopub.status.idle":"2022-04-01T15:07:26.47412Z","shell.execute_reply.started":"2022-04-01T15:07:25.802854Z","shell.execute_reply":"2022-04-01T15:07:26.472857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"id":"_TaRcudRsozf","execution":{"iopub.status.busy":"2022-04-01T15:07:30.100396Z","iopub.execute_input":"2022-04-01T15:07:30.100694Z","iopub.status.idle":"2022-04-01T15:07:30.110403Z","shell.execute_reply.started":"2022-04-01T15:07:30.100663Z","shell.execute_reply":"2022-04-01T15:07:30.109446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining the model parameters","metadata":{}},{"cell_type":"code","source":"from transformers import Wav2Vec2ForCTC\n\nmodel = Wav2Vec2ForCTC.from_pretrained(\n    \"facebook/wav2vec2-large-xlsr-53\" if not last_checkpoint else last_checkpoint, \n    attention_dropout=0.1,\n    hidden_dropout=0.1,\n    feat_proj_dropout=0.1,\n    mask_time_prob=0.05,\n    layerdrop=0.1,\n    gradient_checkpointing=True, \n    ctc_loss_reduction=\"mean\", \n    pad_token_id=processor.tokenizer.pad_token_id,\n    vocab_size=processor.tokenizer.vocab_size\n)","metadata":{"id":"D_JgSQP0srZV","outputId":"8aa7bec5-3eaa-4afa-cb95-31f3e14d0581","execution":{"iopub.status.busy":"2022-04-01T15:07:41.718007Z","iopub.execute_input":"2022-04-01T15:07:41.718289Z","iopub.status.idle":"2022-04-01T15:07:46.826588Z","shell.execute_reply.started":"2022-04-01T15:07:41.718258Z","shell.execute_reply":"2022-04-01T15:07:46.82561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(processor.tokenizer))\nprint(processor.tokenizer.vocab_size)","metadata":{"id":"l7hWBnBysuGO","outputId":"845f8762-800e-428e-f5ba-fa17ede906d8","execution":{"iopub.status.busy":"2022-04-01T15:07:52.361044Z","iopub.execute_input":"2022-04-01T15:07:52.361332Z","iopub.status.idle":"2022-04-01T15:07:52.371692Z","shell.execute_reply.started":"2022-04-01T15:07:52.361301Z","shell.execute_reply":"2022-04-01T15:07:52.370922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.freeze_feature_extractor()","metadata":{"id":"TuBQliJGtEKS","outputId":"b327ac39-77e6-4272-e552-29956a3aa38e","execution":{"iopub.status.busy":"2022-04-01T15:07:55.250992Z","iopub.execute_input":"2022-04-01T15:07:55.251317Z","iopub.status.idle":"2022-04-01T15:07:55.25961Z","shell.execute_reply.started":"2022-04-01T15:07:55.251287Z","shell.execute_reply":"2022-04-01T15:07:55.257885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    # output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-turkish-demo\",\n    # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n    output_dir=save_dir,\n    group_by_length=True,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=2,\n    evaluation_strategy=\"steps\",\n    num_train_epochs=10,\n    fp16=False,\n    save_steps=100, # Just for demo, change it\n    eval_steps=100, # Just for demo, change it\n    logging_steps=100, # Just for demo, change it\n    learning_rate=5e-5,\n    weight_decay=0.1,\n    warmup_steps=100, # Just for demo, change it\n    save_total_limit=2,\n    dataloader_num_workers=4,\n)","metadata":{"id":"eZUaPBr2tG5v","execution":{"iopub.status.busy":"2022-04-01T16:47:47.371269Z","iopub.execute_input":"2022-04-01T16:47:47.371566Z","iopub.status.idle":"2022-04-01T16:47:47.392043Z","shell.execute_reply.started":"2022-04-01T16:47:47.371535Z","shell.execute_reply":"2022-04-01T16:47:47.390562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\n\nfrom typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\nfrom transformers import Trainer\nfrom transformers.trainer import (\n    SequentialDistributedSampler, \n    SequentialSampler,\n    DistributedSamplerWithLoop\n)\nfrom transformers.trainer import is_datasets_available\n\n\nclass CommonVoiceTrainer(Trainer):\n\n    def _get_train_sampler(self):\n        if isinstance(self.train_dataset, torch.utils.data.IterableDataset) or not isinstance(\n            self.train_dataset, collections.abc.Sized\n        ):\n            return None \n        \n        if self.args.world_size <= 1:\n            return RandomSampler(self.train_dataset)\n        elif self.args.parallel_mode == ParallelMode.TPU and not self.args.dataloader_drop_last:\n            # Use a loop for TPUs when drop_last is False to have all batches have the same size.\n            return DistributedSamplerWithLoop(\n                self.train_dataset,\n                batch_size=self.args.per_device_train_batch_size,\n                num_replicas=self.args.world_size,\n                rank=self.args.process_index,\n            )\n        else:\n            return DistributedSampler(\n                self.train_dataset, num_replicas=self.args.world_size, rank=self.args.process_index\n            )\n    \n    def get_train_dataloader(self):\n        if self.train_dataset is None:\n            raise ValueError(\"Trainer: training requires a train_dataset.\")\n        train_sampler = self._get_train_sampler()\n\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.args.train_batch_size,\n            sampler=train_sampler,\n            collate_fn=self.data_collator,\n            drop_last=self.args.dataloader_drop_last,\n            num_workers=self.args.dataloader_num_workers,\n            pin_memory=self.args.dataloader_pin_memory,\n        )\n    \n    def _get_eval_sampler(self, eval_dataset):\n        if self.args.local_rank != -1:\n            return SequentialDistributedSampler(eval_dataset)\n        else:\n            return SequentialSampler(eval_dataset)\n\n\n    def get_eval_dataloader(self, eval_dataset: Optional[Dataset] = None):\n        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n        eval_sampler = self._get_eval_sampler(eval_dataset)\n\n        return DataLoader(\n            eval_dataset,\n            sampler=eval_sampler,\n            batch_size=self.args.eval_batch_size,\n            collate_fn=self.data_collator,\n            drop_last=self.args.dataloader_drop_last,\n            num_workers=self.args.dataloader_num_workers,\n            pin_memory=self.args.dataloader_pin_memory,\n        )","metadata":{"id":"GcO6NYwjtK4J","execution":{"iopub.status.busy":"2022-04-01T15:08:15.812418Z","iopub.execute_input":"2022-04-01T15:08:15.813017Z","iopub.status.idle":"2022-04-01T15:08:15.832303Z","shell.execute_reply.started":"2022-04-01T15:08:15.812967Z","shell.execute_reply":"2022-04-01T15:08:15.831156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = CommonVoiceTrainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"id":"56DShkiytPWO","execution":{"iopub.status.busy":"2022-04-01T15:08:18.974488Z","iopub.execute_input":"2022-04-01T15:08:18.974791Z","iopub.status.idle":"2022-04-01T15:08:19.224864Z","shell.execute_reply.started":"2022-04-01T15:08:18.974759Z","shell.execute_reply":"2022-04-01T15:08:19.223737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if last_checkpoint:\n    print(f\"last_checkpoint: {last_checkpoint}\")\n    train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\nelse:\n    train_result = trainer.train()","metadata":{"id":"xy2tnwNptRvf","outputId":"669518ed-2945-4103-c16f-38bf9ef19c2b","execution":{"iopub.status.busy":"2022-04-01T15:08:21.392305Z","iopub.execute_input":"2022-04-01T15:08:21.392632Z","iopub.status.idle":"2022-04-01T16:47:31.546146Z","shell.execute_reply.started":"2022-04-01T15:08:21.392585Z","shell.execute_reply":"2022-04-01T16:47:31.542096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the Trained Model","metadata":{}},{"cell_type":"markdown","source":"### Saving in local directory","metadata":{}},{"cell_type":"code","source":"metrics = train_result.metrics\nmax_train_samples = len(train_dataset)\nmetrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n\ntrainer.save_model()\n\ntrainer.log_metrics(\"train\", metrics)\ntrainer.save_metrics(\"train\", metrics)\ntrainer.save_state()","metadata":{"id":"15iZYFfStUTk","execution":{"iopub.status.busy":"2022-04-01T14:56:32.540507Z","iopub.execute_input":"2022-04-01T14:56:32.540881Z","iopub.status.idle":"2022-04-01T14:56:35.552294Z","shell.execute_reply.started":"2022-04-01T14:56:32.540844Z","shell.execute_reply":"2022-04-01T14:56:35.55098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading saved model from local directory\nmodel = Wav2Vec2ForCTC.from_pretrained(save_dir).to(\"cuda\")\nprocessor = Wav2Vec2Processor.from_pretrained(save_dir)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T14:56:54.792262Z","iopub.execute_input":"2022-04-01T14:56:54.79269Z","iopub.status.idle":"2022-04-01T14:56:58.393785Z","shell.execute_reply.started":"2022-04-01T14:56:54.792656Z","shell.execute_reply":"2022-04-01T14:56:58.392887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the trained model to HuggingFace repository","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login() #login to HuggingFace to save the model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Install git-lfs to help push the model to a repository in HuggingFace\n%%capture\n!apt install git-lfs\n\n!git config --global credential.helper store","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(\"akanksha-b14/songs-transcription\",use_auth_token=\"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\")\nprocessor.push_to_hub(\"akanksha-b14/songs-transcription\",use_auth_token=\"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\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference on the Validation dataset using the saved model on HuggingFace","metadata":{}},{"cell_type":"code","source":"processor = Wav2Vec2Processor.from_pretrained(\"akanksha-b14/songs-transcription\",use_auth_token=\"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\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"akanksha-b14/songs-transcription\",use_auth_token=\"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\")\nmodel.to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CommonVoiceDataset(\"test.csv\", \"./dataset/\", processor=processor, column_names=None)\nprint(test_dataset[10].keys())","metadata":{"execution":{"iopub.status.busy":"2022-04-01T14:57:02.096613Z","iopub.execute_input":"2022-04-01T14:57:02.096923Z","iopub.status.idle":"2022-04-01T14:57:02.451583Z","shell.execute_reply.started":"2022-04-01T14:57:02.096889Z","shell.execute_reply":"2022-04-01T14:57:02.44971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_values = []\nlabels = []\n\ntest_loader = DataLoader(test_dataset, batch_size=10, collate_fn=data_collator)\nfor data in tqdm(test_loader, total=len(test_loader)):\n    data_input_values = data[\"input_values\"]\n    data_labels = data[\"labels\"]\n\n    input_values.extend([data_input_values[i] for i in range(data_input_values.shape[0])])\n    labels.extend([data_labels[i] for i in range(data_labels.shape[0])])\n\n    # break\n\nitest_loader = {\"input_values\": input_values, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2022-04-01T14:57:14.624683Z","iopub.execute_input":"2022-04-01T14:57:14.625321Z","iopub.status.idle":"2022-04-01T14:59:20.8569Z","shell.execute_reply.started":"2022-04-01T14:57:14.625283Z","shell.execute_reply":"2022-04-01T14:59:20.855639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(itest_loader[\"input_values\"]) == len(itest_loader[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-01T15:00:21.891955Z","iopub.execute_input":"2022-04-01T15:00:21.892264Z","iopub.status.idle":"2022-04-01T15:00:21.903881Z","shell.execute_reply.started":"2022-04-01T15:00:21.89223Z","shell.execute_reply":"2022-04-01T15:00:21.902928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(itest_loader[\"input_values\"]) == len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T15:00:22.677557Z","iopub.execute_input":"2022-04-01T15:00:22.677985Z","iopub.status.idle":"2022-04-01T15:00:22.6877Z","shell.execute_reply.started":"2022-04-01T15:00:22.677952Z","shell.execute_reply":"2022-04-01T15:00:22.686609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.random.randint(0, len(test_dataset))\nprint(f\"idx {idx}\")\n\nprint(f\"TEXT: {test_dataset[idx]['text']}\")\nprint(f\"INPUT: {(itest_loader)['input_values'][0][:5]}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-01T15:00:26.807866Z","iopub.execute_input":"2022-04-01T15:00:26.808169Z","iopub.status.idle":"2022-04-01T15:00:27.039249Z","shell.execute_reply.started":"2022-04-01T15:00:26.808135Z","shell.execute_reply":"2022-04-01T15:00:27.03808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dict = processor(itest_loader[\"input_values\"][idx], return_tensors=\"pt\", padding=True)\n\nlogits = model(input_dict.input_values.to(\"cuda\")).logits\n\npred_ids = torch.argmax(logits, dim=-1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-01T15:00:38.805957Z","iopub.execute_input":"2022-04-01T15:00:38.806292Z","iopub.status.idle":"2022-04-01T15:00:38.946531Z","shell.execute_reply.started":"2022-04-01T15:00:38.806256Z","shell.execute_reply":"2022-04-01T15:00:38.945612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = test_dataset[idx]\n\nprint(\"Prediction:\")\nprint(processor.decode(pred_ids))\n\nprint(\"\\nReference:\")\nprint(sample[\"text\"].lower())\n\n\nspeech, _ = torchaudio.load(sample[\"path\"])\nspeech = speech[0].numpy().squeeze()\n\nspeech = librosa.resample(np.asarray(speech), 48_000, 16_000)\nipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:48:33.364565Z","iopub.execute_input":"2022-04-01T16:48:33.365542Z","iopub.status.idle":"2022-04-01T16:48:33.531267Z","shell.execute_reply.started":"2022-04-01T16:48:33.365507Z","shell.execute_reply":"2022-04-01T16:48:33.52978Z"},"trusted":true},"execution_count":null,"outputs":[]}]}