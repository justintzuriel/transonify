{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dependencies configuration","metadata":{"id":"klqo0hbEaF5L","outputId":"2dd824cf-7c64-4a1e-e0be-68655e964901","execution":{"iopub.status.busy":"2022-04-09T12:53:28.989745Z","iopub.execute_input":"2022-04-09T12:53:28.990118Z","iopub.status.idle":"2022-04-09T12:53:29.791444Z","shell.execute_reply.started":"2022-04-09T12:53:28.990026Z","shell.execute_reply":"2022-04-09T12:53:29.79028Z"}}},{"cell_type":"code","source":"!df -h","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env LC_ALL=C.UTF-8\n%env LANG=C.UTF-8\n%env TRANSFORMERS_CACHE=/content/cache\n%env HF_DATASETS_CACHE=/content/cache\n%env CUDA_LAUNCH_BLOCKING=1","metadata":{"id":"8p8_GHoJaM2P","outputId":"9fc463f1-cf9c-4333-815e-6cd6e4ed9427","execution":{"iopub.status.busy":"2022-04-09T12:53:30.287399Z","iopub.execute_input":"2022-04-09T12:53:30.288286Z","iopub.status.idle":"2022-04-09T12:53:30.302334Z","shell.execute_reply.started":"2022-04-09T12:53:30.288236Z","shell.execute_reply":"2022-04-09T12:53:30.301058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install git+https://github.com/huggingface/datasets.git\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install torchaudio\n!pip install librosa\n!pip install jiwer\n!pip install wandb","metadata":{"id":"0AltjwOtaQYp","execution":{"iopub.status.busy":"2022-04-09T12:53:31.270463Z","iopub.execute_input":"2022-04-09T12:53:31.271255Z","iopub.status.idle":"2022-04-09T12:55:30.521822Z","shell.execute_reply.started":"2022-04-09T12:53:31.271194Z","shell.execute_reply":"2022-04-09T12:55:30.520531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Needed to store training metrics in the WandB environment\n%env WANDB_PROJECT={project-name}\n!wandb login {Token} --relogin","metadata":{"id":"Mm-LQ1nhaSb7","outputId":"360449fb-ff81-488f-9999-c00ddda81c55","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import dependencies for using in the code\nfrom datasets import load_dataset, load_metric\n\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\n\nimport os\nimport string\nimport six\nimport re","metadata":{"id":"0W3usXWKboom","execution":{"iopub.status.busy":"2022-04-09T12:55:30.524672Z","iopub.execute_input":"2022-04-09T12:55:30.525049Z","iopub.status.idle":"2022-04-09T12:55:33.038067Z","shell.execute_reply.started":"2022-04-09T12:55:30.525003Z","shell.execute_reply":"2022-04-09T12:55:33.037059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abs_path_to_metadata = \"../input/metadata/\" #path to metadata.json\nabs_path_to_data = \"../input/utterance-level\" #path to the audio files\nabs_output_path = \"./\" #output folder path","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:55:33.039558Z","iopub.execute_input":"2022-04-09T12:55:33.041683Z","iopub.status.idle":"2022-04-09T12:55:33.04727Z","shell.execute_reply.started":"2022-04-09T12:55:33.041631Z","shell.execute_reply":"2022-04-09T12:55:33.046256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing and Tokenizer vocab creation","metadata":{}},{"cell_type":"code","source":"import json\n\nfile = open(f\"{abs_path_to_metadata}/metadata_split_by_song.json\",'r')\njson_data = file.read()\ndata = json.loads(json_data)\n\ntrain_df = pd.DataFrame()\ntest_df = pd.DataFrame()\nfor value in data.values():\n    res = {}\n    res[\"path\"] = f\"{abs_path_to_data}/{value['path']}/audio.wav\"\n    res[\"sentence\"] = value[\"lyrics\"]\n    if value[\"split\"]==\"train\":\n        train_df = train_df.append(res,ignore_index=True)\n    else:\n        test_df = test_df.append(res,ignore_index=True)\n\ntrain_df.to_csv(f\"{abs_output_path}/train.tsv\",sep=\"\\t\")\ntest_df.to_csv(f\"{abs_output_path}/test.tsv\",sep=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:55:33.05015Z","iopub.execute_input":"2022-04-09T12:55:33.051021Z","iopub.status.idle":"2022-04-09T12:55:43.383245Z","shell.execute_reply.started":"2022-04-09T12:55:33.05097Z","shell.execute_reply":"2022-04-09T12:55:43.382189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Custom normalizer for procesing of annotations\n\ndef normalizer(text):\n    text = text.replace(\"\\\\n\",\"\\n\")\n    text = ' '.join(text.split())\n    text = re.sub(r'''(/|-|_)''',\" \", text)\n    text = text.strip()\n    return text","metadata":{"id":"uO1FEnczbyMF","execution":{"iopub.status.busy":"2022-04-09T12:56:02.389702Z","iopub.execute_input":"2022-04-09T12:56:02.390008Z","iopub.status.idle":"2022-04-09T12:56:02.396939Z","shell.execute_reply.started":"2022-04-09T12:56:02.389968Z","shell.execute_reply":"2022-04-09T12:56:02.395105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{abs_output_path}/train.tsv\", sep=\"\\t\")\n_train_df = train_df.copy()\ntotal_records = len(train_df)\ntrain_df[\"id\"] = range(0, total_records)\nprint(f\"Step 0: {len(train_df)}\")\n\n# train_df[\"path\"] = abs_path_to_data + \"/clips/\" + train_df[\"path\"]\ntrain_df[\"status\"] = train_df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\ntrain_df = train_df.dropna(subset=[\"path\"])\ntrain_df = train_df.drop(\"status\", 1)\nprint(f\"Step 1: {len(train_df)}\")\n\ntrain_df[\"sentence\"] = train_df[\"sentence\"].apply(lambda t: normalizer(t))\ntrain_df = train_df.dropna(subset=[\"sentence\"])\nprint(f\"Step 2: {len(train_df)}\")\n\nterm_a = set(list(range(0, total_records)))\nterm_b = set(train_df[\"id\"].values.tolist())\nremoved_items_train = [_train_df.iloc[index][\"path\"] for index in list(term_a - term_b)]\ntrain_df = train_df.reset_index(drop=True)\ntrain_df.head()","metadata":{"id":"BCDGGF5Fb6Q8","outputId":"1228bc1d-029c-4c4d-b39f-d485af3cdf58","execution":{"iopub.status.busy":"2022-04-09T12:56:08.721091Z","iopub.execute_input":"2022-04-09T12:56:08.72151Z","iopub.status.idle":"2022-04-09T12:56:17.402188Z","shell.execute_reply.started":"2022-04-09T12:56:08.721477Z","shell.execute_reply":"2022-04-09T12:56:17.401144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Items to be removed {len(removed_items_train)}\") # any data in the training dataset which can not be reached should be removed","metadata":{"id":"ogzoGZQhb8mg","outputId":"cc01a499-e81c-4007-cddf-79eca9626a0d","execution":{"iopub.status.busy":"2022-04-09T12:56:17.404497Z","iopub.execute_input":"2022-04-09T12:56:17.405376Z","iopub.status.idle":"2022-04-09T12:56:17.412027Z","shell.execute_reply.started":"2022-04-09T12:56:17.40532Z","shell.execute_reply":"2022-04-09T12:56:17.410783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{abs_output_path}/test.tsv\", sep=\"\\t\")\n\n_test_df = test_df.copy()\ntotal_records = len(test_df)\ntest_df[\"id\"] = range(0, total_records)\nprint(f\"Step 0: {len(test_df)}\")\n\ntest_df[\"status\"] = test_df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\ntest_df = test_df.dropna(subset=[\"path\"])\ntest_df = test_df.drop(\"status\", 1)\nprint(f\"Step 1: {len(test_df)}\")\n\ntest_df[\"sentence\"] = test_df[\"sentence\"].apply(lambda t: normalizer(t))\ntest_df = test_df.dropna(subset=[\"sentence\"])\nprint(f\"Step 2: {len(test_df)}\")\n\nterm_a = set(list(range(0, total_records)))\nterm_b = set(test_df[\"id\"].values.tolist())\nremoved_items_test = [_test_df.iloc[index][\"path\"] for index in list(term_a - term_b)]\ntest_df = test_df.reset_index(drop=True)\ntest_df.head()","metadata":{"id":"thODghZucDfa","outputId":"09cda469-ca4a-4ed6-d75f-86bd2cffd6cc","execution":{"iopub.status.busy":"2022-04-09T12:56:17.413935Z","iopub.execute_input":"2022-04-09T12:56:17.415191Z","iopub.status.idle":"2022-04-09T12:56:18.866314Z","shell.execute_reply.started":"2022-04-09T12:56:17.415143Z","shell.execute_reply":"2022-04-09T12:56:18.865274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Items to be removed {len(removed_items_test)}\") # any data in the test dataset which can not be reached should be removed","metadata":{"id":"c_meMLdqcGS7","outputId":"7649b980-b07a-434a-a17e-ec48d55c5923","execution":{"iopub.status.busy":"2022-04-09T12:56:18.868645Z","iopub.execute_input":"2022-04-09T12:56:18.869601Z","iopub.status.idle":"2022-04-09T12:56:18.875464Z","shell.execute_reply.started":"2022-04-09T12:56:18.869553Z","shell.execute_reply":"2022-04-09T12:56:18.874434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"removed_items = removed_items_train + removed_items_test\n\nfor path in removed_items:\n    if os.path.exists(path):\n        os.remove(path)","metadata":{"id":"4-R3v_69cIZr","execution":{"iopub.status.busy":"2022-04-09T12:56:18.876809Z","iopub.execute_input":"2022-04-09T12:56:18.877589Z","iopub.status.idle":"2022-04-09T12:56:18.886765Z","shell.execute_reply.started":"2022-04-09T12:56:18.877539Z","shell.execute_reply":"2022-04-09T12:56:18.885748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \" \".join(train_df[\"sentence\"].values.tolist() + test_df[\"sentence\"].values.tolist())\nvocab = list(sorted(set(text)))\n\nprint(len(vocab), vocab)","metadata":{"id":"DD-cX_W1cJwA","outputId":"db73084c-31ed-41ad-db74-c76386f32a92","execution":{"iopub.status.busy":"2022-04-09T12:56:18.88808Z","iopub.execute_input":"2022-04-09T12:56:18.889139Z","iopub.status.idle":"2022-04-09T12:56:18.90182Z","shell.execute_reply.started":"2022-04-09T12:56:18.889093Z","shell.execute_reply":"2022-04-09T12:56:18.90067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop('Unnamed: 0',axis=1)\ntest_df = test_df.drop('Unnamed: 0',axis=1)\n\ntrain_df.to_csv(\"./train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\ntest_df.to_csv(\"./test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n\nprint(train_df.shape)\nprint(test_df.shape)","metadata":{"id":"gWCpyVd9cOdx","outputId":"f76364c6-61f7-4c90-ac40-2d07726b9d47","execution":{"iopub.status.busy":"2022-04-09T12:56:22.826614Z","iopub.execute_input":"2022-04-09T12:56:22.827632Z","iopub.status.idle":"2022-04-09T12:56:22.86494Z","shell.execute_reply.started":"2022-04-09T12:56:22.827588Z","shell.execute_reply":"2022-04-09T12:56:22.863891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice_train = load_dataset(\"csv\", data_files={\"train\": \"./train.csv\"}, delimiter=\"\\t\")[\"train\"]\ncommon_voice_test = load_dataset(\"csv\", data_files={\"test\": \"./test.csv\"}, delimiter=\"\\t\")[\"test\"]\n\nprint(common_voice_train)\nprint(common_voice_test)","metadata":{"id":"fJmAkQFScWi9","outputId":"b4c5c872-0e73-4d6f-c32f-1e29cceb1a67","execution":{"iopub.status.busy":"2022-04-09T12:56:34.883945Z","iopub.execute_input":"2022-04-09T12:56:34.88428Z","iopub.status.idle":"2022-04-09T12:56:35.89562Z","shell.execute_reply.started":"2022-04-09T12:56:34.884242Z","shell.execute_reply":"2022-04-09T12:56:35.894562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    display(HTML(df.to_html()))","metadata":{"id":"vlMs77K6cmUk","execution":{"iopub.status.busy":"2022-04-09T12:56:38.780069Z","iopub.execute_input":"2022-04-09T12:56:38.780712Z","iopub.status.idle":"2022-04-09T12:56:38.788811Z","shell.execute_reply.started":"2022-04-09T12:56:38.780674Z","shell.execute_reply":"2022-04-09T12:56:38.787617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_random_elements(common_voice_train.remove_columns([\"path\"]), num_examples=20)","metadata":{"id":"WTFR9COYcpio","outputId":"d8ec781b-029e-45cf-9175-602163ee66b1","execution":{"iopub.status.busy":"2022-04-09T12:56:41.72341Z","iopub.execute_input":"2022-04-09T12:56:41.723725Z","iopub.status.idle":"2022-04-09T12:56:41.740176Z","shell.execute_reply.started":"2022-04-09T12:56:41.723692Z","shell.execute_reply":"2022-04-09T12:56:41.739199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\_\\;\\:\\\"\\“\\%\\‘\\”\\।\\’\\']'\n\ndef remove_special_characters(batch):\n    text = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n    text = normalizer(text)\n    batch[\"text\"] = text\n    return batch","metadata":{"id":"C_iu_869crkt","execution":{"iopub.status.busy":"2022-04-09T12:56:44.435725Z","iopub.execute_input":"2022-04-09T12:56:44.436299Z","iopub.status.idle":"2022-04-09T12:56:44.443147Z","shell.execute_reply.started":"2022-04-09T12:56:44.436257Z","shell.execute_reply":"2022-04-09T12:56:44.442186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice_train = common_voice_train.map(remove_special_characters, remove_columns=[\"sentence\"])\ncommon_voice_test = common_voice_test.map(remove_special_characters, remove_columns=[\"sentence\"])","metadata":{"id":"ju2VsobTdIou","outputId":"e467ab6b-9745-4b25-d7b2-8c8d78ae78cc","execution":{"iopub.status.busy":"2022-04-09T12:56:44.788515Z","iopub.execute_input":"2022-04-09T12:56:44.788812Z","iopub.status.idle":"2022-04-09T12:56:45.608948Z","shell.execute_reply.started":"2022-04-09T12:56:44.788779Z","shell.execute_reply":"2022-04-09T12:56:45.607899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_random_elements(common_voice_train.remove_columns([\"path\"]))","metadata":{"id":"d3sMiGnCdJ2d","outputId":"6540262a-c277-4720-d4b3-c0ed4f8c85e0","execution":{"iopub.status.busy":"2022-04-09T12:56:48.31009Z","iopub.execute_input":"2022-04-09T12:56:48.310754Z","iopub.status.idle":"2022-04-09T12:56:48.325289Z","shell.execute_reply.started":"2022-04-09T12:56:48.310714Z","shell.execute_reply":"2022-04-09T12:56:48.324127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_all_chars(batch):\n    all_text = \" \".join(batch[\"text\"])\n    vocab = list(set(all_text))\n    vocab.append('q')\n    return {\"vocab\": [vocab], \"all_text\": [all_text]}","metadata":{"id":"KOMgDUD-dLVM","execution":{"iopub.status.busy":"2022-04-09T12:56:48.696283Z","iopub.execute_input":"2022-04-09T12:56:48.696738Z","iopub.status.idle":"2022-04-09T12:56:48.702434Z","shell.execute_reply.started":"2022-04-09T12:56:48.6967Z","shell.execute_reply":"2022-04-09T12:56:48.701387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)\nvocab_test = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)","metadata":{"id":"s5XIg5qsdSYL","outputId":"90793878-011d-41d5-978a-1ea0901e6f0c","execution":{"iopub.status.busy":"2022-04-09T12:56:51.371493Z","iopub.execute_input":"2022-04-09T12:56:51.372079Z","iopub.status.idle":"2022-04-09T12:56:51.513182Z","shell.execute_reply.started":"2022-04-09T12:56:51.372044Z","shell.execute_reply":"2022-04-09T12:56:51.512237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))","metadata":{"id":"7FUUtqjwdUDb","execution":{"iopub.status.busy":"2022-04-09T12:56:53.766727Z","iopub.execute_input":"2022-04-09T12:56:53.767025Z","iopub.status.idle":"2022-04-09T12:56:53.772444Z","shell.execute_reply.started":"2022-04-09T12:56:53.76699Z","shell.execute_reply":"2022-04-09T12:56:53.771474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dict = {v: k for k, v in enumerate(vocab_list)}\nvocab_dict","metadata":{"id":"aDoyrYbsdWUv","outputId":"8288cf0a-0d11-4ef4-e492-7c8f85d078f0","execution":{"iopub.status.busy":"2022-04-09T12:56:54.488744Z","iopub.execute_input":"2022-04-09T12:56:54.489546Z","iopub.status.idle":"2022-04-09T12:56:54.498992Z","shell.execute_reply.started":"2022-04-09T12:56:54.489472Z","shell.execute_reply":"2022-04-09T12:56:54.497763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(vocab_dict))\nvocab_dict[\"|\"] = vocab_dict[\" \"]\ndel vocab_dict[\" \"]","metadata":{"id":"383hVNRkdXpr","execution":{"iopub.status.busy":"2022-04-09T12:57:04.530255Z","iopub.execute_input":"2022-04-09T12:57:04.530552Z","iopub.status.idle":"2022-04-09T12:57:04.536159Z","shell.execute_reply.started":"2022-04-09T12:57:04.530519Z","shell.execute_reply":"2022-04-09T12:57:04.535175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dict[\"[UNK]\"] = len(vocab_dict)\nvocab_dict[\"[PAD]\"] = len(vocab_dict)\nlen(vocab_dict)","metadata":{"id":"VpqDwPTDfJQ5","outputId":"6a9d9da0-079c-4172-932f-756af2da8679","execution":{"iopub.status.busy":"2022-04-09T12:57:04.88564Z","iopub.execute_input":"2022-04-09T12:57:04.886362Z","iopub.status.idle":"2022-04-09T12:57:04.89513Z","shell.execute_reply.started":"2022-04-09T12:57:04.886232Z","shell.execute_reply":"2022-04-09T12:57:04.892707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)","metadata":{"id":"TzGtCmYRfKr6","execution":{"iopub.status.busy":"2022-04-09T12:57:07.003348Z","iopub.execute_input":"2022-04-09T12:57:07.003662Z","iopub.status.idle":"2022-04-09T12:57:07.010301Z","shell.execute_reply.started":"2022-04-09T12:57:07.003627Z","shell.execute_reply":"2022-04-09T12:57:07.008994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading an audio sample","metadata":{}},{"cell_type":"code","source":"import torchaudio\nimport librosa\nimport IPython.display as ipd\nimport numpy as np\n\nsample = train_df.iloc[np.random.randint(0, len(train_df))]\n\npath = sample[\"path\"]\nprint(sample[\"sentence\"], \"\\n\")\nspeech = torchaudio.load(path)\nspeech = speech[0].numpy().squeeze() # Wav2Vec2 expects a 1-D tensor array. Using torchaudio we convert it into that format.\n\nspeech = librosa.resample(np.asarray(speech), orig_sr = 48_000, target_sr = 16_000) #All audio samples in Wav2Vec2 are of 16 KHz signal rate. So we resample it\nipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Procedure","metadata":{}},{"cell_type":"code","source":"!mkdir -p ./dataset","metadata":{"id":"t7TR3gWHfUiA","execution":{"iopub.status.busy":"2022-04-09T12:57:07.970489Z","iopub.execute_input":"2022-04-09T12:57:07.971082Z","iopub.status.idle":"2022-04-09T12:57:08.729499Z","shell.execute_reply.started":"2022-04-09T12:57:07.971045Z","shell.execute_reply":"2022-04-09T12:57:08.728183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = []\n\nfor item in tqdm(common_voice_train, position=0, total=len(common_voice_train)):\n    features = common_voice_train.features\n    data = {}\n    for key in features:\n        data[key] = item[key]\n    \n    trainset.append(data)\n\ntrainset = pd.DataFrame(trainset)\ntrainset.to_csv(\"./dataset/train.csv\", sep=\"\\t\")\n\n\ntestset = []\n\nfor item in tqdm(common_voice_test, position=0, total=len(common_voice_test)):\n    features = common_voice_test.features\n    data = {}\n    for key in features:\n        data[key] = item[key]\n    \n    testset.append(data)\n\ntestset = pd.DataFrame(testset)\ntestset.to_csv(\"./dataset/test.csv\", sep=\"\\t\")","metadata":{"id":"K-M1lsCZfWO_","outputId":"9c9fae45-4d9e-4786-b22a-1710b907f105","execution":{"iopub.status.busy":"2022-04-09T12:57:09.147006Z","iopub.execute_input":"2022-04-09T12:57:09.147845Z","iopub.status.idle":"2022-04-09T12:57:09.695976Z","shell.execute_reply.started":"2022-04-09T12:57:09.1478Z","shell.execute_reply":"2022-04-09T12:57:09.694908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset.head()","metadata":{"id":"u2yrsp8IfYKo","outputId":"18181ac1-0d70-4742-82ca-d1cefbb151cd","execution":{"iopub.status.busy":"2022-04-09T12:57:11.002909Z","iopub.execute_input":"2022-04-09T12:57:11.003673Z","iopub.status.idle":"2022-04-09T12:57:11.021037Z","shell.execute_reply.started":"2022-04-09T12:57:11.003621Z","shell.execute_reply":"2022-04-09T12:57:11.018624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset.head()","metadata":{"id":"JKd4ITY2fZz6","outputId":"3fd4e297-7e12-4329-c234-d3cf878e0aa8","execution":{"iopub.status.busy":"2022-04-09T12:57:11.558171Z","iopub.execute_input":"2022-04-09T12:57:11.558809Z","iopub.status.idle":"2022-04-09T12:57:11.570322Z","shell.execute_reply.started":"2022-04-09T12:57:11.55877Z","shell.execute_reply":"2022-04-09T12:57:11.56903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining directory to save model training results\nsave_dir = \"./wav2vec2-base\"\n!ls {save_dir}","metadata":{"id":"mTAdfYoxfb2l","outputId":"60ab4a15-3c8f-4c80-a33c-94a19b6cfa1f","execution":{"iopub.status.busy":"2022-04-09T12:57:12.635163Z","iopub.execute_input":"2022-04-09T12:57:12.635799Z","iopub.status.idle":"2022-04-09T12:57:13.40441Z","shell.execute_reply.started":"2022-04-09T12:57:12.63576Z","shell.execute_reply":"2022-04-09T12:57:13.403286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers.trainer_utils import get_last_checkpoint\n\nlast_checkpoint = None\n\nif os.path.exists(save_dir):\n    last_checkpoint = get_last_checkpoint(save_dir)\n    \nprint(last_checkpoint if last_checkpoint else 0)","metadata":{"id":"N5cW-qHGf2mK","outputId":"6ee62b1d-0432-4d4d-b831-881d457bef55","execution":{"iopub.status.busy":"2022-04-09T12:57:15.48154Z","iopub.execute_input":"2022-04-09T12:57:15.481861Z","iopub.status.idle":"2022-04-09T12:57:19.73009Z","shell.execute_reply.started":"2022-04-09T12:57:15.481827Z","shell.execute_reply":"2022-04-09T12:57:19.729048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading tokenizer from Wav2Vec2 saved directory if it exists\nfrom transformers import Wav2Vec2CTCTokenizer\n\nif not os.path.exists(save_dir):\n    print(\"NotExist\")\n    tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\nelse:\n    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(save_dir)","metadata":{"id":"uw7yqC0Hf__v","outputId":"b1ff244e-bc3e-4c17-d0d8-0db364defe9f","execution":{"iopub.status.busy":"2022-04-09T12:57:23.092743Z","iopub.execute_input":"2022-04-09T12:57:23.093385Z","iopub.status.idle":"2022-04-09T12:57:23.263408Z","shell.execute_reply.started":"2022-04-09T12:57:23.093346Z","shell.execute_reply":"2022-04-09T12:57:23.262161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading feature extractor from Wav2Vec2 saved directory if it exists\nfrom transformers import Wav2Vec2FeatureExtractor\n\nif not os.path.exists(save_dir):\n    print(\"NotExist\")\n    feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\nelse:\n    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(save_dir)","metadata":{"id":"LbjgRGAdgBe2","outputId":"ae35dd06-d96c-4822-a09c-3c57e6f2367c","execution":{"iopub.status.busy":"2022-04-09T12:57:25.823712Z","iopub.execute_input":"2022-04-09T12:57:25.824031Z","iopub.status.idle":"2022-04-09T12:57:25.836703Z","shell.execute_reply.started":"2022-04-09T12:57:25.823996Z","shell.execute_reply":"2022-04-09T12:57:25.835492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a processor with the feature extractor and tokenizer defined above\nfrom transformers import Wav2Vec2Processor\n\nif not os.path.exists(save_dir):\n    print(\"NotExist\")\n    processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\nelse:\n    processor = Wav2Vec2Processor.from_pretrained(save_dir)","metadata":{"id":"71DR-iacgq0n","outputId":"8bcd1baa-26c2-4a8e-c6a4-f08cc17f1e66","execution":{"iopub.status.busy":"2022-04-09T12:57:26.562683Z","iopub.execute_input":"2022-04-09T12:57:26.563523Z","iopub.status.idle":"2022-04-09T12:57:26.575849Z","shell.execute_reply.started":"2022-04-09T12:57:26.563484Z","shell.execute_reply":"2022-04-09T12:57:26.574402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(save_dir):\n    print(\"NotExist\")\n    processor.save_pretrained(save_dir)\n    print(\"Saved!\")","metadata":{"id":"KqZrsq-Ygs8j","outputId":"7ce0657c-eee0-442c-9f71-c0443326fb9d","execution":{"iopub.status.busy":"2022-04-09T12:57:28.166227Z","iopub.execute_input":"2022-04-09T12:57:28.166533Z","iopub.status.idle":"2022-04-09T12:57:28.178115Z","shell.execute_reply.started":"2022-04-09T12:57:28.166499Z","shell.execute_reply":"2022-04-09T12:57:28.176882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice_train[0]","metadata":{"id":"aQPebzl8guxj","outputId":"0e280a84-2f16-4df7-8c7f-c2ca35755c00","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to convert speech to a numpy array","metadata":{}},{"cell_type":"code","source":"import torchaudio\nimport librosa\nimport numpy as np\n\n\ndef speech_file_to_array_fn(file_path):\n    speech_array, _ = torchaudio.load(file_path)\n\n    speech_array = speech_array[0].numpy()\n    speech_array = librosa.resample(np.asarray(speech_array), orig_sr = 48_000, target_sr =16_000)\n    sampling_rate = 16_000\n\n    return speech_array, sampling_rate","metadata":{"id":"QId64dzcgwy2","execution":{"iopub.status.busy":"2022-04-09T12:57:30.109388Z","iopub.execute_input":"2022-04-09T12:57:30.109824Z","iopub.status.idle":"2022-04-09T12:57:30.117357Z","shell.execute_reply.started":"2022-04-09T12:57:30.109787Z","shell.execute_reply":"2022-04-09T12:57:30.115961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing an audio sample after it is converted into a suitable format","metadata":{}},{"cell_type":"code","source":"import IPython.display as ipd\nimport numpy as np\nimport random\n\nrand_int = random.randint(0, len(trainset))\nsample = trainset.iloc[rand_int]\n\ntext = sample[\"text\"]\npath = sample[\"path\"]\n\nspeech_array, sampling_rate = speech_file_to_array_fn(path)\n\nprint(\"Target text:\", text)\nprint(\"Input array shape:\", np.asarray(speech_array).shape)\nprint(\"Sampling rate:\", sampling_rate)\nprint()\n\nipd.Audio(data=np.asarray(speech_array), autoplay=True, rate=16000)","metadata":{"id":"O2Kx6sN0hWW1","outputId":"5f269416-3ff9-42d5-8a7f-48b07302c57e","execution":{"iopub.status.busy":"2022-04-09T12:57:31.759905Z","iopub.execute_input":"2022-04-09T12:57:31.760542Z","iopub.status.idle":"2022-04-09T12:57:31.867574Z","shell.execute_reply.started":"2022-04-09T12:57:31.760506Z","shell.execute_reply":"2022-04-09T12:57:31.866306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchaudio\nimport librosa\n\nimport numpy as np\nimport pandas as pd\n\nfrom torch.utils.data import Dataset, DataLoader\nimport os\n\n\nclass CommonVoiceDataset(Dataset):\n\n    def __init__(self, csv_file, root_dir, processor, column_names=None, sep=\"\\t\"):\n        self.data = pd.read_csv(os.path.join(root_dir, csv_file), sep=sep)\n        self.processor = processor\n        self.column_names = column_names\n\n    def __len__(self):\n        return len(self.data)\n\n\n    def speech_file_to_array_fn(self, batch):\n        speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n        batch[\"speech\"] = speech_array[0].numpy()\n        batch[\"sampling_rate\"] = sampling_rate\n        batch[\"target_text\"] = batch[\"text\"]\n        return batch\n\n    \n    def resample(self, batch):\n        batch[\"speech\"] = librosa.resample(np.asarray(batch[\"speech\"]), orig_sr = 48_000, target_sr = 16_000)\n        batch[\"sampling_rate\"] = 16_000\n        return batch\n\n    \n    def prepare_dataset(self, batch, column_names=None):\n        batch[\"input_values\"] = self.processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"]).input_values[0].tolist()\n\n        with self.processor.as_target_processor():\n            batch[\"labels\"] = self.processor(batch[\"target_text\"]).input_ids\n\n        if column_names and isinstance(column_names, list):\n            batch = {name: batch[name] for name in column_names}\n        \n        return batch\n\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        batch = self.data.iloc[idx].copy()\n        batch = batch.to_dict()\n        batch = self.speech_file_to_array_fn(batch)\n        batch = self.resample(batch)\n        batch = self.prepare_dataset(batch, self.column_names)\n\n        return batch ","metadata":{"id":"Iu_ttTuYhX6b","execution":{"iopub.status.busy":"2022-04-09T12:57:34.905948Z","iopub.execute_input":"2022-04-09T12:57:34.906616Z","iopub.status.idle":"2022-04-09T12:57:34.922388Z","shell.execute_reply.started":"2022-04-09T12:57:34.906577Z","shell.execute_reply":"2022-04-09T12:57:34.921037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    \"\"\"\n    Data collator that will dynamically pad the inputs received.\n    Args:\n        processor (:class:`~transformers.Wav2Vec2Processor`)\n            The processor used for proccessing the data.\n        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n            among:\n            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n              sequence if provided).\n            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n              maximum acceptable input length for the model if that argument is not provided.\n            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n              different lengths).\n        max_length (:obj:`int`, `optional`):\n            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n        max_length_labels (:obj:`int`, `optional`):\n            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n        pad_to_multiple_of (:obj:`int`, `optional`):\n            If set will pad the sequence to a multiple of the provided value.\n            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n            7.5 (Volta).\n    \"\"\"\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n    max_length: Optional[int] = None\n    max_length_labels: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    pad_to_multiple_of_labels: Optional[int] = None\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lenghts and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                max_length=self.max_length_labels,\n                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"id":"GqLuiIkvhmxp","execution":{"iopub.status.busy":"2022-04-09T12:57:36.338431Z","iopub.execute_input":"2022-04-09T12:57:36.338814Z","iopub.status.idle":"2022-04-09T12:57:36.360342Z","shell.execute_reply.started":"2022-04-09T12:57:36.338769Z","shell.execute_reply":"2022-04-09T12:57:36.359171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"id":"HZZbr9gmhpa_","execution":{"iopub.status.busy":"2022-04-09T12:57:38.023875Z","iopub.execute_input":"2022-04-09T12:57:38.024188Z","iopub.status.idle":"2022-04-09T12:57:38.029484Z","shell.execute_reply.started":"2022-04-09T12:57:38.024154Z","shell.execute_reply":"2022-04-09T12:57:38.028147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CommonVoiceDataset(\"train.csv\", \"./dataset/\", processor=processor, column_names=[\"input_values\", \"labels\"])\ntest_dataset = CommonVoiceDataset(\"test.csv\", \"./dataset/\", processor=processor, column_names=[\"input_values\", \"labels\"])","metadata":{"id":"VvUbht6nhqgt","execution":{"iopub.status.busy":"2022-04-09T12:57:38.356995Z","iopub.execute_input":"2022-04-09T12:57:38.358113Z","iopub.status.idle":"2022-04-09T12:57:38.375975Z","shell.execute_reply.started":"2022-04-09T12:57:38.358062Z","shell.execute_reply":"2022-04-09T12:57:38.375022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))\nprint(len(test_dataset))","metadata":{"id":"OWH9C9q5hrk4","outputId":"81022de8-d9ee-492d-c7d9-40fe6984d675","execution":{"iopub.status.busy":"2022-04-09T12:57:39.314382Z","iopub.execute_input":"2022-04-09T12:57:39.314687Z","iopub.status.idle":"2022-04-09T12:57:39.321576Z","shell.execute_reply.started":"2022-04-09T12:57:39.314653Z","shell.execute_reply":"2022-04-09T12:57:39.320492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_dataset:\n    print(batch.keys())\n    print(type(batch))\n    # print(batch)\n    break","metadata":{"id":"ULeHv5LLhsjM","outputId":"02823779-8052-4737-b2c4-449181b4e021","execution":{"iopub.status.busy":"2022-04-09T12:57:41.112363Z","iopub.execute_input":"2022-04-09T12:57:41.112978Z","iopub.status.idle":"2022-04-09T12:57:42.16916Z","shell.execute_reply.started":"2022-04-09T12:57:41.112938Z","shell.execute_reply":"2022-04-09T12:57:42.167966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wer_metric = load_metric(\"wer\")","metadata":{"id":"DRYCAR32hvxD","outputId":"0151262c-4d9b-4647-d99d-291853e00141","execution":{"iopub.status.busy":"2022-04-09T12:57:42.171148Z","iopub.execute_input":"2022-04-09T12:57:42.171417Z","iopub.status.idle":"2022-04-09T12:57:43.128966Z","shell.execute_reply.started":"2022-04-09T12:57:42.171385Z","shell.execute_reply":"2022-04-09T12:57:43.127905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"id":"weQZT8_0hx04","execution":{"iopub.status.busy":"2022-04-09T12:57:43.858926Z","iopub.execute_input":"2022-04-09T12:57:43.859887Z","iopub.status.idle":"2022-04-09T12:57:43.869308Z","shell.execute_reply.started":"2022-04-09T12:57:43.859835Z","shell.execute_reply":"2022-04-09T12:57:43.867669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining the model parameters","metadata":{}},{"cell_type":"code","source":"from transformers import Wav2Vec2ForCTC\n\nmodel = Wav2Vec2ForCTC.from_pretrained(\n    \"facebook/wav2vec2-base\" if not last_checkpoint else last_checkpoint, \n    attention_dropout=0.1,\n    hidden_dropout=0.1,\n    feat_proj_dropout=0.1,\n    mask_time_prob=0.05,\n    layerdrop=0.1,\n    gradient_checkpointing=True, \n    ctc_loss_reduction=\"mean\", \n    pad_token_id=processor.tokenizer.pad_token_id,\n    vocab_size=processor.tokenizer.vocab_size\n)\nmodel.config.ctc_zero_infinity = True","metadata":{"id":"V_owuCGth4bj","outputId":"46a954c9-ca5a-4540-d5a3-9083ba68bc60","execution":{"iopub.status.busy":"2022-04-09T12:57:49.701925Z","iopub.execute_input":"2022-04-09T12:57:49.702278Z","iopub.status.idle":"2022-04-09T12:58:05.96928Z","shell.execute_reply.started":"2022-04-09T12:57:49.702237Z","shell.execute_reply":"2022-04-09T12:58:05.968383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(processor.tokenizer))\nprint(processor.tokenizer.vocab_size)","metadata":{"id":"kcr59rGHh6fl","outputId":"8bd456c9-c514-4ee7-ef8c-e808b733c042","execution":{"iopub.status.busy":"2022-04-09T12:58:05.973935Z","iopub.execute_input":"2022-04-09T12:58:05.974812Z","iopub.status.idle":"2022-04-09T12:58:05.981825Z","shell.execute_reply.started":"2022-04-09T12:58:05.974763Z","shell.execute_reply":"2022-04-09T12:58:05.980749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.freeze_feature_extractor()","metadata":{"id":"6YxAajKdiCJQ","execution":{"iopub.status.busy":"2022-04-09T12:58:05.983242Z","iopub.execute_input":"2022-04-09T12:58:05.984266Z","iopub.status.idle":"2022-04-09T12:58:06.144824Z","shell.execute_reply.started":"2022-04-09T12:58:05.984193Z","shell.execute_reply":"2022-04-09T12:58:06.143523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=save_dir,\n    group_by_length=True,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=2,\n    evaluation_strategy=\"steps\",\n    num_train_epochs=30,\n    fp16=False,\n    save_steps=100, \n    eval_steps=100, \n    logging_steps=100,\n    learning_rate=5e-5,\n    weight_decay=0.1,\n    warmup_steps=500,\n    save_total_limit=2,\n    dataloader_num_workers=4\n)","metadata":{"id":"gMkin_6liDxw","execution":{"iopub.status.busy":"2022-04-09T12:58:06.148673Z","iopub.execute_input":"2022-04-09T12:58:06.14928Z","iopub.status.idle":"2022-04-09T12:58:06.233015Z","shell.execute_reply.started":"2022-04-09T12:58:06.149229Z","shell.execute_reply":"2022-04-09T12:58:06.23199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\n\nfrom typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\nfrom transformers import Trainer\nfrom transformers.trainer import (\n    SequentialDistributedSampler, \n    SequentialSampler,\n    DistributedSamplerWithLoop\n)\nfrom transformers.trainer import is_datasets_available\n\n\nclass CommonVoiceTrainer(Trainer):\n\n    def _get_train_sampler(self):\n        if isinstance(self.train_dataset, torch.utils.data.IterableDataset) or not isinstance(\n            self.train_dataset, collections.abc.Sized\n        ):\n            return None \n        \n        if self.args.world_size <= 1:\n            return RandomSampler(self.train_dataset)\n        elif self.args.parallel_mode == ParallelMode.TPU and not self.args.dataloader_drop_last:\n            # Use a loop for TPUs when drop_last is False to have all batches have the same size.\n            return DistributedSamplerWithLoop(\n                self.train_dataset,\n                batch_size=self.args.per_device_train_batch_size,\n                num_replicas=self.args.world_size,\n                rank=self.args.process_index,\n            )\n        else:\n            return DistributedSampler(\n                self.train_dataset, num_replicas=self.args.world_size, rank=self.args.process_index\n            )\n    \n    def get_train_dataloader(self):\n        if self.train_dataset is None:\n            raise ValueError(\"Trainer: training requires a train_dataset.\")\n        train_sampler = self._get_train_sampler()\n\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.args.train_batch_size,\n            sampler=train_sampler,\n            collate_fn=self.data_collator,\n            drop_last=self.args.dataloader_drop_last,\n            num_workers=self.args.dataloader_num_workers,\n            pin_memory=self.args.dataloader_pin_memory,\n        )\n    \n    def _get_eval_sampler(self, eval_dataset):\n        if self.args.local_rank != -1:\n            return SequentialDistributedSampler(eval_dataset)\n        else:\n            return SequentialSampler(eval_dataset)\n\n\n    def get_eval_dataloader(self, eval_dataset: Optional[Dataset] = None):\n        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n        eval_sampler = self._get_eval_sampler(eval_dataset)\n\n        return DataLoader(\n            eval_dataset,\n            sampler=eval_sampler,\n            batch_size=self.args.eval_batch_size,\n            collate_fn=self.data_collator,\n            drop_last=self.args.dataloader_drop_last,\n            num_workers=self.args.dataloader_num_workers,\n            pin_memory=self.args.dataloader_pin_memory,\n        )","metadata":{"id":"9YOl574piNXP","execution":{"iopub.status.busy":"2022-04-09T12:58:06.23483Z","iopub.execute_input":"2022-04-09T12:58:06.235549Z","iopub.status.idle":"2022-04-09T12:58:06.438175Z","shell.execute_reply.started":"2022-04-09T12:58:06.235466Z","shell.execute_reply":"2022-04-09T12:58:06.437176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = CommonVoiceTrainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=processor.feature_extractor\n)","metadata":{"id":"T5kjHl8HiO9z","execution":{"iopub.status.busy":"2022-04-09T12:58:06.440037Z","iopub.execute_input":"2022-04-09T12:58:06.440396Z","iopub.status.idle":"2022-04-09T12:58:12.686989Z","shell.execute_reply.started":"2022-04-09T12:58:06.440351Z","shell.execute_reply":"2022-04-09T12:58:12.685775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If a checkpoint is stored from before, use that for continuing training, else start from 0\nif last_checkpoint:\n    print(f\"last_checkpoint: {last_checkpoint}\")\n    train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\nelse:\n    train_result = trainer.train()","metadata":{"id":"mVruIh5uiRgR","outputId":"83ccc9b8-fbab-4b71-bfad-623f2f4641fc","execution":{"iopub.status.busy":"2022-04-09T12:58:12.691359Z","iopub.execute_input":"2022-04-09T12:58:12.692134Z","iopub.status.idle":"2022-04-09T19:19:17.397734Z","shell.execute_reply.started":"2022-04-09T12:58:12.692098Z","shell.execute_reply":"2022-04-09T19:19:17.396779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the Trained Model","metadata":{}},{"cell_type":"code","source":"metrics = train_result.metrics\nmax_train_samples = len(train_dataset)\nmetrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n\ntrainer.save_model()\n\ntrainer.log_metrics(\"train\", metrics)\ntrainer.save_metrics(\"train\", metrics)\ntrainer.save_state()","metadata":{"id":"tn5UP3jxip1M","execution":{"iopub.status.busy":"2022-04-09T19:19:25.816177Z","iopub.execute_input":"2022-04-09T19:19:25.816755Z","iopub.status.idle":"2022-04-09T19:19:26.475402Z","shell.execute_reply.started":"2022-04-09T19:19:25.816718Z","shell.execute_reply":"2022-04-09T19:19:26.474414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the trained model and processor to local directory","metadata":{}},{"cell_type":"code","source":"trainer.save_model('./')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the trained model to HuggingFace repository","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login() #login to HuggingFace to save the model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Install git-lfs to help push the model to a repository in HuggingFace\n%%capture\n!apt install git-lfs\n\n!git config --global credential.helper store","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(\"songs_transcription_wav2vec_base2\",use_auth_token=\"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\")\nprocessor.push_to_hub(\"songs_transcription_wav2vec_base2\",use_auth_token=\"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\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference on the Validation dataset using the saved model on HuggingFace","metadata":{}},{"cell_type":"code","source":"test_dataset = CommonVoiceDataset(\"test.csv\", \"./dataset/\", processor=processor, column_names=None)\nprint(test_dataset[10].keys())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_values = []\nlabels = []\n\ntest_loader = DataLoader(test_dataset, batch_size=10, collate_fn=data_collator)\nfor data in tqdm(test_loader, total=len(test_loader)):\n    data_input_values = data[\"input_values\"]\n    data_labels = data[\"labels\"]\n\n    input_values.extend([data_input_values[i] for i in range(data_input_values.shape[0])])\n    labels.extend([data_labels[i] for i in range(data_labels.shape[0])])\n\n    # break\n\nitest_loader = {\"input_values\": input_values, \"labels\": labels}","metadata":{"id":"jeC109R6yaz9","outputId":"3a2dabb2-5700-4ccc-e837-b2024804be0a","execution":{"iopub.status.busy":"2022-04-09T19:19:41.074751Z","iopub.execute_input":"2022-04-09T19:19:41.075273Z","iopub.status.idle":"2022-04-09T19:21:01.078851Z","shell.execute_reply.started":"2022-04-09T19:19:41.075222Z","shell.execute_reply":"2022-04-09T19:21:01.077753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(itest_loader[\"input_values\"]) == len(itest_loader[\"labels\"])","metadata":{"id":"iHNusLXNyc6J","execution":{"iopub.status.busy":"2022-04-09T19:21:07.265266Z","iopub.execute_input":"2022-04-09T19:21:07.265602Z","iopub.status.idle":"2022-04-09T19:21:07.273111Z","shell.execute_reply.started":"2022-04-09T19:21:07.26557Z","shell.execute_reply":"2022-04-09T19:21:07.27142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(itest_loader[\"input_values\"]) == len(test_dataset)","metadata":{"id":"pqNgFlMGylGw","execution":{"iopub.status.busy":"2022-04-09T19:21:08.34402Z","iopub.execute_input":"2022-04-09T19:21:08.344435Z","iopub.status.idle":"2022-04-09T19:21:08.352113Z","shell.execute_reply.started":"2022-04-09T19:21:08.344387Z","shell.execute_reply":"2022-04-09T19:21:08.350945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.random.randint(0, len(test_dataset))\nprint(f\"idx {idx}\")\n\nprint(f\"TEXT: {test_dataset[idx]['text']}\")\nprint(f\"INPUT: {(itest_loader)['input_values'][0][:5]}\")","metadata":{"id":"N_dux3YyynuJ","outputId":"c2321c8e-f175-4545-86ec-5dd0162dc570","execution":{"iopub.status.busy":"2022-04-09T19:21:09.183649Z","iopub.execute_input":"2022-04-09T19:21:09.18394Z","iopub.status.idle":"2022-04-09T19:21:09.333196Z","shell.execute_reply.started":"2022-04-09T19:21:09.183909Z","shell.execute_reply":"2022-04-09T19:21:09.33216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dict = processor(itest_loader[\"input_values\"][idx], return_tensors=\"pt\", padding=True)\n\nlogits = model(input_dict.input_values.to(\"cuda\")).logits\n\npred_ids = torch.argmax(logits, dim=-1)[0]","metadata":{"id":"f9GlL-u1ypfR","outputId":"9cd95175-7f06-4309-9cc8-42c220eccce4","execution":{"iopub.status.busy":"2022-04-09T19:21:20.682026Z","iopub.execute_input":"2022-04-09T19:21:20.682351Z","iopub.status.idle":"2022-04-09T19:21:20.77409Z","shell.execute_reply.started":"2022-04-09T19:21:20.682319Z","shell.execute_reply":"2022-04-09T19:21:20.773106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = test_dataset[idx]\n\nprint(\"Prediction:\")\nprint(processor.decode(pred_ids))\n\nprint(\"\\nReference:\")\nprint(sample[\"text\"].lower())\n\n\nspeech = torchaudio.load(sample[\"path\"])\nspeech = speech[0].numpy().squeeze()\n\nspeech = librosa.resample(np.asarray(speech), 48_000, 16_000)\nipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)","metadata":{"id":"LovYyiDoytDY","outputId":"229d2f2d-eb34-4797-d218-85deedbf01c1","execution":{"iopub.status.busy":"2022-04-09T19:21:25.849035Z","iopub.execute_input":"2022-04-09T19:21:25.849907Z","iopub.status.idle":"2022-04-09T19:21:26.086514Z","shell.execute_reply.started":"2022-04-09T19:21:25.849845Z","shell.execute_reply":"2022-04-09T19:21:26.08539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers.trainer_utils import get_last_checkpoint\n\nlast_checkpoint = None\n\nif os.path.exists(save_dir):\n    last_checkpoint = get_last_checkpoint(save_dir)\n    \nprint(last_checkpoint if last_checkpoint else 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T19:28:46.830697Z","iopub.execute_input":"2022-04-09T19:28:46.831026Z","iopub.status.idle":"2022-04-09T19:28:46.844512Z","shell.execute_reply.started":"2022-04-09T19:28:46.830993Z","shell.execute_reply":"2022-04-09T19:28:46.842891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processor_hf = Wav2Vec2Processor.from_pretrained(\"akanksha-b14/songs_transcription_wav2vec_base2\",use_auth_token=\"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\")\nmodel_hf = Wav2Vec2ForCTC.from_pretrained(\"akanksha-b14/songs_transcription_wav2vec_base2\",use_auth_token=\"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\")\nmodel_hf.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T19:29:39.229583Z","iopub.execute_input":"2022-04-09T19:29:39.229864Z","iopub.status.idle":"2022-04-09T19:30:01.961993Z","shell.execute_reply.started":"2022-04-09T19:29:39.229832Z","shell.execute_reply":"2022-04-09T19:30:01.960687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchaudio\nfrom datasets import Dataset, load_metric\nfrom transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\nimport re\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\ndf_test = pd.read_csv(\"./test.tsv\", sep=\"\\t\")\ntest_dataset = Dataset.from_pandas(df_test)\nwer = load_metric(\"wer\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T19:30:01.964738Z","iopub.execute_input":"2022-04-09T19:30:01.965194Z","iopub.status.idle":"2022-04-09T19:30:02.639164Z","shell.execute_reply.started":"2022-04-09T19:30:01.965144Z","shell.execute_reply":"2022-04-09T19:30:02.638147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\_\\;\\:\\\"\\“\\%\\‘\\”\\।\\’\\'\\&]'\nresampler = torchaudio.transforms.Resample(48_000, 16_000)\n\ndef normalizer(text):\n    # Use your custom normalizer\n    text = text.replace(\"\\\\n\",\"\\n\")\n    text = ' '.join(text.split())\n#     text = re.sub(r'([a-z]+)','',text,flags=re.IGNORECASE)\n#     text = re.sub(r'''(/|-|_)''',\" \", text)\n    text = text.strip()\n    return text\n\ndef speech_file_to_array_fn(batch):\n#     batch[\"sentence\"] = normalizer(batch[\"sentence\"])\n    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()+ \" \"\n    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n    return batch\n\ntest_dataset_new = test_dataset.map(speech_file_to_array_fn)\n\n# Preprocessing the datasets.\n# We need to read the aduio files as arrays\ndef evaluate(batch):\n    inputs = processor_hf(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n    with torch.no_grad():\n        logits = model_hf(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n    pred_ids = torch.argmax(logits, dim=-1)\n    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n    return batch\n\nresult = test_dataset.map(evaluate, batched=True, batch_size=8)\nprint(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T19:30:57.878725Z","iopub.execute_input":"2022-04-09T19:30:57.879079Z","iopub.status.idle":"2022-04-09T19:31:01.839405Z","shell.execute_reply.started":"2022-04-09T19:30:57.879036Z","shell.execute_reply":"2022-04-09T19:31:01.83801Z"},"trusted":true},"execution_count":null,"outputs":[]}]}